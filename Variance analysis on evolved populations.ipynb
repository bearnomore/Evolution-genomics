{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'G:\\\\Dropbox (Vetsigian lab)\\\\Vetsigian lab Team Folder\\\\Ye\\\\Genomics\\\\'\n",
    "# path = 'E:\\\\CMT_project\\\\CMT project\\\\'\n",
    "genomic_table_coelicolor = pd.read_csv(path + 'genomic_table_coelicolor.csv')\n",
    "path = 'G:\\\\Dropbox (Vetsigian lab)\\\\Vetsigian lab Team Folder\\\\Ye\\Genomics\\\\Community mutants\\\\antiSMASH_Streptomyces_coelicolor\\\\'\n",
    "# path = 'E:\\\\CMT_project\\\\CMT project\\\\'\n",
    "filename = 'index.html'\n",
    "cluster_info = pd.read_html(path+filename)[0].drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import filled variance files of each population\n",
    "\n",
    "filepath = 'G:\\\\Dropbox (Vetsigian lab)\\\\Vetsigian lab Team Folder\\\\Ye\\\\Genomics\\\\Community mutants\\\\'\n",
    "folders = ['PopA', 'PopB', 'PopC', 'PopD', 'PopE', 'PopF', 'PopG', 'PopH']\n",
    "\n",
    "vcfA = pd.read_csv(filepath + folders[0] + '\\\\vcfA_filled.csv')\n",
    "# vcfB = pd.read_csv(filepath + folders[1] + '\\\\vcfB_filled.csv')\n",
    "vcfC = pd.read_csv(filepath + folders[2] + '\\\\vcfC_filled.csv')\n",
    "vcfD = pd.read_csv(filepath + folders[3] + '\\\\vcfD_filled.csv')\n",
    "# vcfE = pd.read_csv(filepath + folders[4] + '\\\\vcfE_filled.csv')\n",
    "# vcfF = pd.read_csv(filepath + folders[5] + '\\\\vcfF_filled.csv')\n",
    "# vcfG = pd.read_csv(filepath + folders[6] + '\\\\vcfG_filled.csv')\n",
    "# vcfH = pd.read_csv(filepath + folders[7] + '\\\\vcfH_filled.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcfA.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variance_abundance_along_timepoints(vcfs,time_points, pop_lab):\n",
    "    '''\n",
    "    Inputs:\n",
    "    vcfs = variance files of teh query population(e.g. PopA) \n",
    "    timepoints \n",
    "    pop_lab = population labels (e.g. 'A')\n",
    "    \n",
    "    Outputs:\n",
    "    plot of variance abundance vs. timepoints\n",
    "    '''\n",
    "    VF_cols = vcfs.columns[8::2]\n",
    "    for i in range(0, len(vcfs)):\n",
    "        plt.plot(time_points, vcfs.iloc[i][VF_cols])\n",
    "    plt.xlabel('Community Generations')\n",
    "    plt.ylabel('Variance Frequency')\n",
    "    plt.title('Population ' + pop_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PopA variance profile visualization\n",
    "colnames  = vcfA.columns\n",
    "timepoints = [int(vf[0]) for vf in colnames[8::2]]\n",
    "coverage = colnames[9::2]\n",
    "# Find variances covered through all tested generations/timepoints\n",
    "mask = np.sum(vcfA[coverage] > 20, axis = 1) == len(timepoints)\n",
    "vcfA_full = vcfA.loc[mask]\n",
    "plot_variance_abundance_along_timepoints(vcfA_full,timepoints, 'A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. PopC variance profile visualization\n",
    "colnames  = vcfC.columns\n",
    "timepoints = [int(vf[0]) for vf in colnames[8::2]]\n",
    "coverage = colnames[9::2]\n",
    "# Find variances covered through all tested generations/timepoints\n",
    "mask = np.sum(vcfC[coverage] > 20, axis = 1) == len(timepoints)\n",
    "vcfC_full = vcfC.loc[mask]\n",
    "plot_variance_abundance_along_timepoints(vcfC_full,timepoints, 'C')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcfC_full.iloc[150:160][colnames[8:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. PopD variance profile visualization\n",
    "colnames  = vcfD.columns\n",
    "timepoints = [int(vf[0]) for vf in colnames[8::2]]\n",
    "coverage = colnames[9::2]\n",
    "# Find variances covered at least 20x through all tested generations/timepoints\n",
    "mask = np.sum(vcfD[coverage] > 20, axis = 1) == len(timepoints)\n",
    "vcfD_full = vcfD.loc[mask]\n",
    "plot_variance_abundance_along_timepoints(vcfD_full,timepoints, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = colnames[8::2]\n",
    "msk1 = np.sum(vcfD_full[vf[0:4]] > 0, axis = 1) == 4\n",
    "D1 = vcfD_full.loc[msk1]\n",
    "plot_variance_abundance_along_timepoints(D1,timepoints, 'D1')\n",
    "D1_loc1 = D1['Minimum']\n",
    "D1_loc2 = D1['Maximum']\n",
    "plt.figure()\n",
    "plt.plot(D1_loc1, D1_loc2, 'bo')\n",
    "plt.xticks(np.arange(0, 9000000, 10**6), rotation = 90)\n",
    "plt.yticks(np.arange(0, 9000000, 10**6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down123 = np.sum(vcfD_full[vf[0:3]] == 0, axis = 1) == 3\n",
    "down678 = np.sum(vcfD_full[vf[4:]] == 0, axis = 1) == 3\n",
    "up4 = vcfD_full[vf[3]] > 0\n",
    "print(len(down123), len(down678), len(up4), len(vcfD_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_4up_only = np.sum(pd.concat([down123, down678, up4], axis =1), axis = 1) == 3\n",
    "D_4up_only = vcfD_full.loc[msk_4up_only]\n",
    "plot_variance_abundance_along_timepoints(D_4up_only,timepoints, 'D_4up_only')\n",
    "loc1 = D_4up_only['Minimum']\n",
    "loc2 = D_4up_only['Maximum']\n",
    "plt.figure()\n",
    "plt.plot(loc1, loc2, 'bo')\n",
    "plt.xticks(np.arange(0, 9000000, 10**6), rotation = 90)\n",
    "plt.yticks(np.arange(0, 9000000, 10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "down1234 = np.sum(vcfD_full[vf[0:4]] == 0, axis = 1) == 4\n",
    "down78 = np.sum(vcfD_full[vf[5:7]] == 0, axis = 1) == 2\n",
    "up6 = vcfD_full[vf[4]] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_6up_only = np.sum(pd.concat([down1234, down78, up6], axis =1), axis = 1) == 3\n",
    "D_6up_only = vcfD_full.loc[msk_6up_only]\n",
    "plot_variance_abundance_along_timepoints(D_6up_only,timepoints, 'D_6up_only')\n",
    "loc1 = D_6up_only['Minimum']\n",
    "loc2 = D_6up_only['Maximum']\n",
    "plt.figure()\n",
    "plt.plot(loc1, loc2, 'bo')\n",
    "plt.xticks(np.arange(0, 9000000, 10**6), rotation = 90)\n",
    "plt.yticks(np.arange(0, 9000000, 10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_6up_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Build variance correlation for each population\n",
    "colA_vf = vcfA.columns[8::2]\n",
    "dist_mat = np.array(1 - vcfA[colA_vf].T.corr())\n",
    "\n",
    "m = dist_mat.shape[0]\n",
    "r = np.arange(m)\n",
    "mask = r[:, None]<r\n",
    "dist_mat2 = np.nan_to_num(dist_mat[mask])\n",
    "\n",
    "dist_mat2[dist_mat2 < 0] = 0\n",
    "\n",
    "methods = ['single', 'complete', 'average', 'ward', 'weighted', 'centroid']\n",
    "Z = dict()\n",
    "c = dict()\n",
    "coph_dists = dict()\n",
    "plt.figure()\n",
    "\n",
    "for med in methods:\n",
    "    Z[med] = linkage(dist_mat2, med)\n",
    "    c[med], coph_dists[med] = cophenet(Z[med], dist_mat2)\n",
    "    plt.bar(med, c[med], color = 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(dist_mat2, 'average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dendrogram_profile(profile_link):\n",
    "    # calculate full dendrogram\n",
    "    # save_path = 'E:\\\\CMT_project\\\\CMT project\\\\clustering_common_variances.png'\n",
    "#     plt.figure()\n",
    "    plt.figure(1, figsize=(12, 6))\n",
    "    plt.title('Hierarchical Clustering of variances', size = 16)\n",
    "    plt.xlabel('variance index', size = 14)\n",
    "    plt.ylabel('distance', size = 14)\n",
    "    R = dendrogram(profile_link,\n",
    "#                    truncate_mode='lastp',  # show only the last p merged clusters\n",
    "#                    p=50,  # show only the last p merged clusters\n",
    "                   show_leaf_counts=False,  # otherwise numbers in brackets are counts\n",
    "                   leaf_rotation=90.,\n",
    "                   leaf_font_size=12,\n",
    "                   show_contracted=True,  # to get a distribution impression in truncated branches\n",
    "                   color_threshold = 0.85,\n",
    "#                    orientation = 'left'\n",
    "                  )\n",
    "#     save_path = 'E:\\\\CMT_project\\\\CMT project\\\\hierarchical_clustering_of_common_variances.png'\n",
    "#     plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dendrogram_profile(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster_for_SNPs(cluster_info, snp2geno_cat):\n",
    "    '''\n",
    "    Inputs:\n",
    "    cluster_info = the cluster information dataframe from the antiSMASH website\n",
    "    snp2geno_cat = df of SNPs contribute to the categorized dynamics of the variance frequency \n",
    "            of the communities along time,generated by find_genetic_region_for_SNPs()\n",
    "    Outputs:\n",
    "    The cluster info the genes belong to if found\n",
    "    '''\n",
    "    cluster_range = cluster_info.apply(lambda row: range(int(row['From']), int(row['To'])+1), axis = 1)\n",
    "    SNP_ranges = snp2geno_cat.reset_index().apply(lambda row: range(int(row['Minimum']), int(row['Maximum']) + 1), axis = 1)\n",
    "    \n",
    "    colnames_cluster = cluster_info.columns\n",
    "    colnames_genes = snp2geno_cat.columns\n",
    "    \n",
    "    cluster_slice = pd.DataFrame(columns= colnames_cluster)\n",
    "    gene_slice = pd.DataFrame(columns = colnames_genes)     \n",
    "    \n",
    "    count1 = 0\n",
    "    for snp_r in SNP_ranges:\n",
    "        snp_r = set(snp_r)\n",
    "        count2 = 0\n",
    "        for clk in cluster_range:\n",
    "            ovp = snp_r.intersection(clk)\n",
    "            if bool(ovp):\n",
    "                temp1 = snp2geno_cat.iloc[count1]\n",
    "                gene_slice = gene_slice.append(temp1)\n",
    "                temp2 = cluster_info.iloc[count2]\n",
    "                cluster_slice = cluster_slice.append(temp2)\n",
    "            count2 = count2 + 1\n",
    "        count1 = count1 + 1\n",
    "        \n",
    "    # Concat the two dfs\n",
    "    df1 = gene_slice.reset_index().drop(\"index\", axis = 1)    \n",
    "    df2 = cluster_slice.reset_index().drop(\"index\", axis = 1)[[\"Cluster\", \"Type\"]]\n",
    "    gene2cluster = pd.concat([df1, df2], axis = 1)\n",
    "\n",
    "    return gene2cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_d = 0.85\n",
    "clusters = fcluster(Z, max_d, criterion='distance')\n",
    "clustered_profile = dict()\n",
    "for cl in set(clusters):\n",
    "    clustered_profile[cl] = vcfA.loc[clusters == cl]\n",
    "    df_cluster = find_cluster_for_SNPs(cluster_info, clustered_profile[cl])\n",
    "    cluster = df_cluster['Cluster'].values\n",
    "    Type = df_cluster['Type'].values\n",
    "    print(str(cl) + ':' + cluster + ',' + Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rpy2.robjects import r, pandas2ri\n",
    "# from rpy2.robjects.packages import importr\n",
    "# pandas2ri.activate()\n",
    "# base = importr(\"base\")\n",
    "# pvclust = importr(\"pvclust\")\n",
    "# data = robjects.DataFrame.from_csvfile(filepath + folders[0] + '\\\\vcfA_filled.csv')\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = robjects.IntVector(np.arange(9, 21, 2))\n",
    "# cols\n",
    "# subset = data.rx(True, cols)\n",
    "# is_numeric(subset)\n",
    "# # result = pvclust.pvclust(data, method_hclust = \"average\", method_dist = \"correlation\", nboot = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_profile_per_population(vcfs_pop, var_T1):\n",
    "    cols = vcfs_pop.columns\n",
    "    cols1 = cols[0:7]\n",
    "    cols2 = cols[7:]\n",
    "    profile = pd.DataFrame(columns = cols)\n",
    "    for ind in range(len(var_T1)):\n",
    "        vari = var_T1.iloc[ind]\n",
    "        msk = np.sum(vcfs_pop[['Name', 'Minimum', 'Maximum']] == vari, axis = 1) == 3\n",
    "        if sum(msk) > 1:\n",
    "            temp1 = vcfs_pop.loc[msk,cols1].iloc[0]        \n",
    "            temp2 = vcfs_pop.loc[msk,cols2].sum()\n",
    "            temp = pd.concat([temp1, temp2])\n",
    "            profile = profile.append(temp, ignore_index = True)\n",
    "        else:\n",
    "            profile = profile.append(vcfs_pop.loc[msk, cols], ignore_index = True)\n",
    "    return profile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
